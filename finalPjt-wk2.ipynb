{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas_profiling'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7c5e0f8daa76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas_profiling\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Python SQL toolkit and Object Relational Mapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas_profiling'"
     ]
    }
   ],
   "source": [
    "# matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "\n",
    "# Pandas and Numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling as pp\n",
    "\n",
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import connection string (youll need to create this)\n",
    "from config import conn\n",
    "\n",
    "# create the engine\n",
    "engine = create_engine(conn)\n",
    "Base = automap_base()\n",
    "\n",
    "# reflect an existing database into a new model\n",
    "Base.prepare(engine, reflect=True)\n",
    "\n",
    "# reflect the tables\n",
    "#Recession_Indicator = Base.classes.recession_indicator_by_day\n",
    "Recession_Indicator = Base.classes.us_recession\n",
    "Historical_Price = Base.classes.historical_price_by_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to conver the date\n",
    "def convDate(elDate):\n",
    "    return datetime.fromordinal(datetime(1900, 1, 1).toordinal() + elDate - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our session (link) from Python to the DB\n",
    "session = Session(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create df from Historical_Price table\n",
    "\n",
    "results = []\n",
    "\n",
    "results = session.query(Historical_Price.date, \\\n",
    "                        Historical_Price.open, \\\n",
    "                        Historical_Price.high, \\\n",
    "                        Historical_Price.low, \\\n",
    "                        Historical_Price.close, \\\n",
    "                        Historical_Price.ticker)\n",
    "\n",
    "\n",
    "price_df = pd.DataFrame(results).set_index(['date'])\n",
    "price_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create df from Recession_Indicator table\n",
    "results = []\n",
    "\n",
    "results = session.query(Recession_Indicator.date, \\\n",
    "                        Recession_Indicator.recession_indicator, \\\n",
    "                        Recession_Indicator.country)\n",
    "\n",
    "\n",
    "#recession_df = pd.DataFrame(results).set_index(['country'])\n",
    "recession_df = pd.DataFrame(results)\n",
    "\n",
    "recession_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA on Historical Price Table, showing 64,708 observations and 4 characteristics\n",
    "price_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA to see label of each column\n",
    "price_df.columns.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data has only object values\n",
    "- No variable column has null or missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA on Historical Price Table, beginning with basic statistics\n",
    "price_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Observations\n",
    "- dataset comprises of 64,708 observations and 4 chracteriestics\n",
    "- out of which x is dependent variable and the remaining x are independent variables\n",
    "- Data needs to be redone.  Not capturing mean, Standard deviation etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA on Historical Price Table, to get further info on the data showing that no variable column has null values.\n",
    "price_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA on Historical Price Table continued with pandas-profiling\n",
    "pp.ProfileReport(price_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA on Historical Recession Indicator, beginning with basic statistics\n",
    "recession_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA on Historical Recession Indicator continued with pandas-profiling\n",
    "pp.ProfileReport(recession_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA Data Visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create the engine\n",
    "engine = create_engine(conn)\n",
    "Base = automap_base()\n",
    "\n",
    "# reflect an existing database into a new model\n",
    "Base.prepare(engine, reflect=True)\n",
    "\n",
    "# reflect the tables\n",
    "#Recession_Indicator = Base.classes.recession_indicator_by_day\n",
    "Recession_Indicator = Base.classes.us_recession\n",
    "Historical_Price = Base.classes.historical_price_by_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = recession_df.copy()\n",
    "X = X.drop(\"recession_indicator\", axis=1)\n",
    "X = pd.get_dummies(X, columns=[\"country\"])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cols = recession_df[\"recession_indicator\"] \n",
    "\n",
    "y = pd.DataFrame()\n",
    "\n",
    "y[\"recession_indicator\"] = y_cols\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['recession_indicator'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X_train, X_test, y_train, y_test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_cols, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the logistic regression model\n",
    "log_classifier = LogisticRegression(solver=\"lbfgs\", max_iter=200)\n",
    "\n",
    "# Train the model\n",
    "log_classifier.fit(X_train,y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = log_classifier.predict(X_test)\n",
    "print(f\" Logistic regression model accuracy: {accuracy_score(y_test,y_pred):.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap( {INSERT DF HERE} .isnull(),cbar=False,yticklabels=False,cmap = 'viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap( {INSERT OUR DF HERE} .corr(),cmap='Blues',annot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quality correlation matrix\n",
    "k = #number of variables for heatmap\n",
    "cols = {OUR DF HERE} .corr().nlargest(k, 'quality')['quality'].index\n",
    "cm = {\"\"}[cols].corr()\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(cm, annot=True, cmap = 'viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = {INSERT DF HERE} .columns.values\n",
    "number_of_columns=12\n",
    "number_of_rows = len(l)-1/number_of_columns\n",
    "plt.figure(figsize=(number_of_columns,5*number_of_rows))\n",
    "for i in range(0,len(l)):\n",
    "    plt.subplot(number_of_rows + 1,number_of_columns,i+1)\n",
    "    sns.set_style('whitegrid')\n",
    "    sns.boxplot(df[l[i]],color='red',orient='v')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2*number_of_columns,5*number_of_rows))\n",
    "for i in range(0,len(l)):\n",
    "    plt.subplot(number_of_rows + 1,number_of_columns,i+1)\n",
    "    sns.distplot({INSERT OUR DF HERE}[l[i]],kde=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
